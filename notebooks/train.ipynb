{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from transformers import AutoTokenizer, AutoModelForCausalLM, TrainingArguments, Trainer, DataCollatorForSeq2Seq, TrainerCallback\n",
    "from datasets import load_dataset\n",
    "from collections import deque\n",
    "import datetime\n",
    "import os\n",
    "\n",
    "\n",
    "BASE_MODEL = \"BEE-spoke-data/smol_llama-101M-GQA\"\n",
    "MAX_LEN = 512\n",
    "\n",
    "# load model\n",
    "model = AutoModelForCausalLM.from_pretrained(BASE_MODEL)\n",
    "tokenizer = AutoTokenizer.from_pretrained(BASE_MODEL)\n",
    "\n",
    "if tokenizer.pad_token is None:\n",
    "    tokenizer.add_special_tokens({'pad_token': tokenizer.eos_token})\n",
    "tokenizer.padding_side = \"left\"\n",
    "model.resize_token_embeddings(len(tokenizer))\n",
    "\n",
    "# load data\n",
    "dataset = load_dataset(\"blanchon/snac_llm_parler_tts\", split='train[0:10000]') \n",
    "dataset = dataset.train_test_split(test_size=0.3, seed=42)\n",
    "\n",
    "def prepare_sample(sample):\n",
    "\n",
    "    input_ids = tokenizer(sample[\"text\"]+\"[audio]\", padding=False, truncation=True, max_length=256)[\"input_ids\"]\n",
    "    target_ids = [int(t) for t in sample[\"snac24khz\"].split(\" \")][:256]\n",
    "    labels = [-100] * len(input_ids) + target_ids\n",
    "    return {\"input_ids\": input_ids+target_ids, \"labels\": labels}\n",
    "\n",
    "tokenized_train_dataset = dataset[\"train\"].map(prepare_sample, batched=False)\n",
    "tokenized_val_dataset = dataset[\"test\"].map(prepare_sample, batched=False)\n",
    "\n",
    "data_collator = DataCollatorForSeq2Seq(tokenizer, model=model)  #for dynamic padding\n",
    "\n",
    "\n",
    "def reconstruct_codec(flattened):\n",
    "\n",
    "    flattened = deque(flattened) # makes it efficient\n",
    "    lists = [[],[],[]]\n",
    "\n",
    "    while len(flattened)>=7:\n",
    "        lists[0] += [flattened.popleft()]\n",
    "        lists[1] += [flattened.popleft()]\n",
    "        lists[2] += [flattened.popleft()]\n",
    "        lists[2] += [flattened.popleft()]\n",
    "        lists[1] += [flattened.popleft()]\n",
    "        lists[2] += [flattened.popleft()]\n",
    "        lists[2] += [flattened.popleft()]\n",
    "\n",
    "    return [torch.tensor(l, dtype=torch.int).unsqueeze(0).to(\"cuda\") for l in lists]\n",
    "\n",
    "def flat_codec(codec):\n",
    "\n",
    "    flattened = []\n",
    "    for i in range(len(codec[0][0])):\n",
    "        flattened.append(codec[0][0][i])\n",
    "        flattened.append(codec[1][0][2*i])\n",
    "        flattened.append(codec[2][0][4*i])\n",
    "\n",
    "        if 4*i + 1 < len(codec[2][0]):\n",
    "            flattened.append(codec[2][0][4*i + 1])\n",
    "\n",
    "        if 2*i + 1 < len(codec[1][0]):\n",
    "            flattened.append(codec[1][0][2*i + 1])\n",
    "            flattened.append(codec[2][0][4*i + 2])\n",
    "\n",
    "            if 4*i + 3 < len(codec[2][0]):\n",
    "                flattened.append(codec[2][0][4*i + 3])\n",
    "\n",
    "    return flattened"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save a soundfile each epoch\n",
    "# import soundfile as sf\n",
    "# from snac import SNAC\n",
    "\n",
    "# snac = SNAC.from_pretrained(\"hubertsiuzdak/snac_24khz\").eval()\n",
    "# snac = snac.cuda()\n",
    "\n",
    "# class SaveCallback(TrainerCallback):\n",
    "\n",
    "#     def on_evaluate(self, args, state, control, model, **kwargs):\n",
    "        \n",
    "#         input_ids = tokenizer(dataset[\"test\"][0][\"text\"]+\"[audio]\", return_tensors=\"pt\", padding=False, truncation=True, max_length=256)[\"input_ids\"].to(model.device)\n",
    "#         with torch.no_grad():\n",
    "#             outputs = model.generate(input_ids, max_length=300, pad_token_id=tokenizer.eos_token_id) #MAX_LEN\n",
    "#         codes = reconstruct_codec(outputs[0])\n",
    "\n",
    "#         audio_hat = snac.decode(codes) # problem with the wrong indices this breaks CUDA\n",
    "#         sf.write(f\"step_{state.global_step}.wav\", audio_hat.cpu().detach().numpy().squeeze(), 24000)\n",
    "#         print(\"Failed to create audio from created snac tokens\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train\n",
    "experiment = datetime.datetime.now().strftime(\"%Y-%m-%d_%H:%M-\") + BASE_MODEL\n",
    "folder = f\"./results/{experiment}\"\n",
    "os.makedirs(folder, exist_ok=False)\n",
    "\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=TrainingArguments(\n",
    "        output_dir=folder,\n",
    "        eval_strategy=\"steps\",\n",
    "        eval_steps=1000,\n",
    "        learning_rate=3e-5,\n",
    "        per_device_train_batch_size=4,\n",
    "        num_train_epochs=1,  \n",
    "        weight_decay=0.01,\n",
    "        push_to_hub=False,\n",
    "        logging_dir='./logs',\n",
    "        logging_steps=10,\n",
    "        save_steps=5000,\n",
    "        save_total_limit=10,\n",
    "        fp16=True,  \n",
    "        lr_scheduler_type=\"cosine\",\n",
    "        warmup_steps=500  # Number of steps to perform learning rate warm-up\n",
    "    ),\n",
    "    train_dataset=tokenized_train_dataset,\n",
    "    eval_dataset=tokenized_val_dataset,\n",
    "    data_collator=data_collator,\n",
    "    #callbacks=[SaveCallback]\n",
    ")\n",
    "\n",
    "trainer.train()\n",
    "trainer.save_model(f\"{folder}/trained_model\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "default-6IQEWI-N-py3.10",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
